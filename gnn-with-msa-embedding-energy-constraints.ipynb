{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":87793,"databundleVersionId":11553390,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:09:16.447136Z","iopub.execute_input":"2025-04-06T04:09:16.447413Z","iopub.status.idle":"2025-04-06T04:09:16.721186Z","shell.execute_reply.started":"2025-04-06T04:09:16.447389Z","shell.execute_reply":"2025-04-06T04:09:16.720294Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"train_labels = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_labels.csv')\ntrain_sequences = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:09:38.474012Z","iopub.execute_input":"2025-04-06T04:09:38.474383Z","iopub.status.idle":"2025-04-06T04:09:38.757206Z","shell.execute_reply.started":"2025-04-06T04:09:38.474362Z","shell.execute_reply":"2025-04-06T04:09:38.756519Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_labels.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:09:39.838158Z","iopub.execute_input":"2025-04-06T04:09:39.838473Z","iopub.status.idle":"2025-04-06T04:09:39.858264Z","shell.execute_reply.started":"2025-04-06T04:09:39.838426Z","shell.execute_reply":"2025-04-06T04:09:39.857633Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"         ID resname  resid     x_1        y_1     z_1\n0  1SCL_A_1       G      1  13.760 -25.974001   0.102\n1  1SCL_A_2       G      2   9.310 -29.638000   2.669\n2  1SCL_A_3       G      3   5.529 -27.813000   5.878\n3  1SCL_A_4       U      4   2.678 -24.900999   9.793\n4  1SCL_A_5       G      5   1.827 -20.136000  11.793","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>resname</th>\n      <th>resid</th>\n      <th>x_1</th>\n      <th>y_1</th>\n      <th>z_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1SCL_A_1</td>\n      <td>G</td>\n      <td>1</td>\n      <td>13.760</td>\n      <td>-25.974001</td>\n      <td>0.102</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1SCL_A_2</td>\n      <td>G</td>\n      <td>2</td>\n      <td>9.310</td>\n      <td>-29.638000</td>\n      <td>2.669</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1SCL_A_3</td>\n      <td>G</td>\n      <td>3</td>\n      <td>5.529</td>\n      <td>-27.813000</td>\n      <td>5.878</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1SCL_A_4</td>\n      <td>U</td>\n      <td>4</td>\n      <td>2.678</td>\n      <td>-24.900999</td>\n      <td>9.793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1SCL_A_5</td>\n      <td>G</td>\n      <td>5</td>\n      <td>1.827</td>\n      <td>-20.136000</td>\n      <td>11.793</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_sequences.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:09:42.887618Z","iopub.execute_input":"2025-04-06T04:09:42.887882Z","iopub.status.idle":"2025-04-06T04:09:42.896608Z","shell.execute_reply.started":"2025-04-06T04:09:42.887860Z","shell.execute_reply":"2025-04-06T04:09:42.895742Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  target_id                            sequence temporal_cutoff  \\\n0    1SCL_A       GGGUGCUCAGUACGAGAGGAACCGCACCC      1995-01-26   \n1    1RNK_A  GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU      1995-02-27   \n2    1RHT_A            GGGACUGACGAUCACGCAGUCUAU      1995-06-03   \n3    1HLX_A                GGGAUAACUUCGGUUGUCCC      1995-09-15   \n4    1HMH_E  GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU      1995-12-07   \n\n                                         description  \\\n0               THE SARCIN-RICIN LOOP, A MODULAR RNA   \n1  THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...   \n2  24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...   \n3  P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID   \n4  THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...   \n\n                                       all_sequences  \n0  >1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...  \n1  >1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...  \n2  >1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...  \n3  >1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...  \n4  >1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target_id</th>\n      <th>sequence</th>\n      <th>temporal_cutoff</th>\n      <th>description</th>\n      <th>all_sequences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1SCL_A</td>\n      <td>GGGUGCUCAGUACGAGAGGAACCGCACCC</td>\n      <td>1995-01-26</td>\n      <td>THE SARCIN-RICIN LOOP, A MODULAR RNA</td>\n      <td>&gt;1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1RNK_A</td>\n      <td>GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU</td>\n      <td>1995-02-27</td>\n      <td>THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...</td>\n      <td>&gt;1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1RHT_A</td>\n      <td>GGGACUGACGAUCACGCAGUCUAU</td>\n      <td>1995-06-03</td>\n      <td>24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...</td>\n      <td>&gt;1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1HLX_A</td>\n      <td>GGGAUAACUUCGGUUGUCCC</td>\n      <td>1995-09-15</td>\n      <td>P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID</td>\n      <td>&gt;1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1HMH_E</td>\n      <td>GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU</td>\n      <td>1995-12-07</td>\n      <td>THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...</td>\n      <td>&gt;1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\n# Extract IDs with NaN values in train_labels\nnan_ids = train_labels.loc[train_labels[['x_1', 'y_1', 'z_1']].isna().any(axis=1), 'ID']\n\n# Remove the last underscore and number (extract base ID)\nnan_base_ids = nan_ids.str.rsplit('_', n=1).str[0].unique()\n\n# Drop rows from train_labels where base ID matches\ntrain_labels = train_labels[~train_labels[\"ID\"].str.rsplit('_', n=1).str[0].isin(nan_base_ids)]\n\n# Drop rows from train_sequences where base ID matches\ntrain_sequences = train_sequences[~train_sequences[\"target_id\"].isin(nan_base_ids)]\n\n# Reset index if needed\ntrain_labels.reset_index(drop=True, inplace=True)\ntrain_sequences.reset_index(drop=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:09:43.958391Z","iopub.execute_input":"2025-04-06T04:09:43.958692Z","iopub.status.idle":"2025-04-06T04:09:44.179591Z","shell.execute_reply.started":"2025-04-06T04:09:43.958671Z","shell.execute_reply":"2025-04-06T04:09:44.178760Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# **📌 Step 1: Improving the GNN Model**\n### **1.1 Use a Graph Transformer Instead of GCN**\nInstead of a basic **Graph Convolutional Network (GCN)**, we can use a **Graph Transformer**, which is better at capturing **long-range interactions** in RNA.\n\n### **🔹 Code: Graph Transformer Model**\n","metadata":{}},{"cell_type":"code","source":"!pip install torch-geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:09:47.287610Z","iopub.execute_input":"2025-04-06T04:09:47.287897Z","iopub.status.idle":"2025-04-06T04:09:52.389699Z","shell.execute_reply.started":"2025-04-06T04:09:47.287874Z","shell.execute_reply":"2025-04-06T04:09:52.388721Z"}},"outputs":[{"name":"stdout","text":"Collecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch_geometric.nn import TransformerConv\n\nclass RNA_Transformer_GNN(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers=3):\n        super(RNA_Transformer_GNN, self).__init__()\n        \n        self.layers = nn.ModuleList()\n        for _ in range(num_layers):\n            self.layers.append(TransformerConv(hidden_dim, hidden_dim, heads=4))\n\n        self.fc_input = nn.Linear(input_dim, hidden_dim)\n        self.fc_output = nn.Linear(hidden_dim, 3)  # Predict (x, y, z)\n\n    def forward(self, x, edge_index):\n        x = self.fc_input(x)\n        for layer in self.layers:\n            x = torch.relu(layer(x, edge_index))\n        return self.fc_output(x)\n\n# Model initialization\nmodel = RNA_Transformer_GNN(input_dim=4, hidden_dim=128)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:09:54.925590Z","iopub.execute_input":"2025-04-06T04:09:54.925921Z","iopub.status.idle":"2025-04-06T04:10:01.701047Z","shell.execute_reply.started":"2025-04-06T04:09:54.925892Z","shell.execute_reply":"2025-04-06T04:10:01.700057Z"}},"outputs":[{"name":"stdout","text":"RNA_Transformer_GNN(\n  (layers): ModuleList(\n    (0-2): 3 x TransformerConv(128, 128, heads=4)\n  )\n  (fc_input): Linear(in_features=4, out_features=128, bias=True)\n  (fc_output): Linear(in_features=128, out_features=3, bias=True)\n)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"🔹 **Why is this better?**\n- **TransformerConv** captures **long-range dependencies** in RNA (better than GCN).  \n- **Multi-head attention** improves structural context awareness.  \n\n---\n\n### **1.2 Use MSA Embeddings Instead of One-Hot Encoding**\nWe can replace **one-hot encoding** with **MSA Transformer embeddings** (e.g., from ESM-1b or RNA-specific models).\n\n### **🔹 Code: Extract MSA Embeddings**","metadata":{}},{"cell_type":"code","source":"!pip install multimolecule","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:12:13.212592Z","iopub.execute_input":"2025-04-06T04:12:13.213040Z","iopub.status.idle":"2025-04-06T04:12:17.840354Z","shell.execute_reply.started":"2025-04-06T04:12:13.213018Z","shell.execute_reply":"2025-04-06T04:12:17.839242Z"}},"outputs":[{"name":"stdout","text":"Collecting multimolecule\n  Downloading multimolecule-0.0.6-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from multimolecule) (1.2.1)\nCollecting chanfig>=0.0.105 (from multimolecule)\n  Downloading chanfig-0.0.109-py3-none-any.whl.metadata (13 kB)\nCollecting danling>=0.3.11 (from danling[torch]>=0.3.11->multimolecule)\n  Downloading danling-0.3.13-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from multimolecule) (3.3.1)\nRequirement already satisfied: StrEnum in /usr/local/lib/python3.10/dist-packages (from multimolecule) (0.4.15)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from multimolecule) (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from multimolecule) (4.47.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from chanfig>=0.0.105->multimolecule) (6.0.2)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from chanfig>=0.0.105->multimolecule) (4.12.2)\nRequirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (from danling>=0.3.11->danling[torch]>=0.3.11->multimolecule) (3.1.43)\nCollecting lazy-imports (from danling>=0.3.11->danling[torch]>=0.3.11->multimolecule)\n  Downloading lazy_imports-0.4.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from danling>=0.3.11->danling[torch]>=0.3.11->multimolecule) (4.67.1)\nCollecting torcheval (from danling[torch]>=0.3.11->multimolecule)\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (from danling[torch]>=0.3.11->multimolecule) (1.6.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->multimolecule) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->multimolecule) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->multimolecule) (5.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->multimolecule) (0.29.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate->multimolecule) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->multimolecule) (3.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->multimolecule) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->multimolecule) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->multimolecule) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->multimolecule) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->multimolecule) (1.3.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->multimolecule) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->multimolecule) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->multimolecule) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->multimolecule) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->multimolecule) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->multimolecule) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->multimolecule) (3.11.12)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->multimolecule) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->multimolecule) (0.21.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->multimolecule) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->multimolecule) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->multimolecule) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->multimolecule) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->multimolecule) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->multimolecule) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->multimolecule) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->multimolecule) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate->multimolecule) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate->multimolecule) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate->multimolecule) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate->multimolecule) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate->multimolecule) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate->multimolecule) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->multimolecule) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->multimolecule) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->multimolecule) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->multimolecule) (2025.1.31)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython->danling>=0.3.11->danling[torch]>=0.3.11->multimolecule) (4.0.11)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->multimolecule) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->multimolecule) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->multimolecule) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->multimolecule) (2025.1)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics->danling[torch]>=0.3.11->multimolecule) (0.12.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython->danling>=0.3.11->danling[torch]>=0.3.11->multimolecule) (5.0.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics->danling[torch]>=0.3.11->multimolecule) (75.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->multimolecule) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate->multimolecule) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate->multimolecule) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate->multimolecule) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate->multimolecule) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate->multimolecule) (2024.2.0)\nDownloading multimolecule-0.0.6-py3-none-any.whl (377 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chanfig-0.0.109-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading danling-0.3.13-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lazy_imports-0.4.0-py3-none-any.whl (12 kB)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval, lazy-imports, chanfig, danling, multimolecule\nSuccessfully installed chanfig-0.0.109 danling-0.3.13 lazy-imports-0.4.0 multimolecule-0.0.6 torcheval-0.0.7\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#divide long input string into chunks\n\ndef chunk_sequence(sequence, max_length=1024, overlap=128):\n    \"\"\"\n    Splits a sequence into overlapping chunks.\n    \n    Args:\n        sequence (str): RNA sequence (ACGU).\n        max_length (int): Maximum model token length.\n        overlap (int): Number of overlapping tokens.\n\n    Returns:\n        list of str: List of sequence chunks.\n    \"\"\"\n    chunks = []\n    start = 0\n    while start < len(sequence):\n        chunk = sequence[start:start + max_length]\n        chunks.append(chunk)\n        start += max_length - overlap  # Move forward with overlap\n        if len(chunk) < max_length:\n            break  # Stop if last chunk is short\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:12:17.841465Z","iopub.execute_input":"2025-04-06T04:12:17.841697Z","iopub.status.idle":"2025-04-06T04:12:17.846482Z","shell.execute_reply.started":"2025-04-06T04:12:17.841676Z","shell.execute_reply":"2025-04-06T04:12:17.845512Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# from transformers import EsmTokenizer, EsmForMaskedLM\n\n# # Load pretrained ESM model\n# tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm1b_t33_650M_UR50S\")\n# model = EsmForMaskedLM.from_pretrained(\"facebook/esm1b_t33_650M_UR50S\", output_hidden_states=True)\n\n# print(\"Max Position Embeddings:\", model.config.max_position_embeddings)\n\nfrom multimolecule import RnaTokenizer, RnaFmModel\ntokenizer = RnaTokenizer.from_pretrained(\"multimolecule/rnafm\")\nmodel = RnaFmModel.from_pretrained(\"multimolecule/rnafm\")\n\ndef get_msa_embedding(sequence):\n    \"\"\"Generate MSA embedding for RNA sequence\"\"\"\n    # Chunk it\n    chunks = chunk_sequence(sequence)\n    print(chunks)\n\n    # Tokenize each chunk\n    tokenized_chunks = [tokenizer(chunk, return_tensors=\"pt\", add_special_tokens=False) for chunk in chunks]\n\n    #inputs = tokenizer(sequence, return_tensors=\"pt\", add_special_tokens=False)\n    # print(\"Token IDs:\", inputs[\"input_ids\"])\n    # print(\"Vocab size:\", model.config.vocab_size)\n\n    # if \"position_ids\" in inputs and (inputs[\"position_ids\"] >= model.config.max_position_embeddings).any():\n    #     raise ValueError(\"Position ID out of range!\")\n    \n    with torch.no_grad():\n        # Get model output (logits and hidden states)\n        # print(f\"Processing sequence: {sequence}\")\n        # print(\"Tokenized input_ids:\", inputs[\"input_ids\"])\n        # print(\"Input shape:\", inputs[\"input_ids\"].shape)\n        \n        #output = model(**inputs)\n        embeddings = [model(**chunk).last_hidden_state.squeeze(0) for chunk in tokenized_chunks]\n        \n        # Accessing the last hidden state from the output\n    return embeddings\n\n# Example usage\nmsa_embedding = get_msa_embedding(\"GGGAAACCC\")\nprint(msa_embedding[0].shape)  # Expected: (seq_length, embedding_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:12:17.847942Z","iopub.execute_input":"2025-04-06T04:12:17.848138Z","iopub.status.idle":"2025-04-06T04:12:37.775087Z","shell.execute_reply.started":"2025-04-06T04:12:17.848122Z","shell.execute_reply":"2025-04-06T04:12:37.774285Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d57fc8759406431d82d1944209485d1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/77.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c44f93c09b964234a46dbe89a6e75ae5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/224 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c3782fc50bc427a975f156979c8ca7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbc260d850844f90a70311e9d49a162b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/398M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bc00fbea4b44a5b85f91ed828a37923"}},"metadata":{}},{"name":"stderr","text":"Some weights of RnaFmModel were not initialized from the model checkpoint at multimolecule/rnafm and are newly initialized: ['rnafm.pooler.dense.bias', 'rnafm.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"['GGGAAACCC']\ntorch.Size([9, 640])\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"🔹 **Why is this better?**\n- **MSA embeddings** capture **evolutionary conservation** from large protein/RNA databases.\n- **Pretrained models** (like ESM or RNA-specific transformers) generalize well to new sequences.","metadata":{}},{"cell_type":"markdown","source":"🔹 4. Graph-Aware Aggregation (For Graph-Based Models)\nInstead of treating the sequence as linear, map it to a graph first and aggregate node features:","metadata":{}},{"cell_type":"code","source":"def create_chunk_graph(chunk_embeddings, window_size=3):\n    \"\"\"\n    This function takes the chunk embeddings and generates a graph structure.\n    Each chunk will be a node, and edges will connect consecutive chunks.\n    \"\"\"\n    num_chunks = len(chunk_embeddings)\n\n    # Create edge_index to connect consecutive chunks (nodes)\n    edges = []\n    for i in range(num_chunks - 1):\n        edges.append([i, i + 1])  # Edge between consecutive nodes\n\n    # Convert to tensor form\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()  # Shape: [2, num_edges]\n\n    # Create the graph structure\n    graph = Data(x=chunk_embeddings, edge_index=edge_index)\n    return graph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:12:37.775894Z","iopub.execute_input":"2025-04-06T04:12:37.776324Z","iopub.status.idle":"2025-04-06T04:12:37.780719Z","shell.execute_reply.started":"2025-04-06T04:12:37.776306Z","shell.execute_reply":"2025-04-06T04:12:37.779710Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import torch_geometric.nn as pyg_nn\nfrom torch_geometric.data import Data\n\nclass GNN_Aggregator(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        self.conv1 = pyg_nn.GraphConv(hidden_dim, hidden_dim)\n        self.conv2 = pyg_nn.GraphConv(hidden_dim, hidden_dim)\n\n    def forward(self, graph):\n        x, edge_index = graph.x, graph.edge_index\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index)\n        return x  # (num_nodes, hidden_dim)\n\n# Example usage\nrna_graph = create_chunk_graph(msa_embedding)  # Assign embeddings as node features\n# print(f\"rna_graph.x shape: {rna_graph.x.shape}\")\n# print(f\"rna_graph.edge_index shape: {rna_graph.edge_index.shape}\")\nprint(f\"rna_graph.edge_index: {rna_graph.edge_index}\")\n\ngnn_aggregator = GNN_Aggregator(hidden_dim=640)\nfinal_representation = gnn_aggregator(rna_graph)\nprint(final_representation.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:17:24.241599Z","iopub.execute_input":"2025-04-06T04:17:24.241925Z","iopub.status.idle":"2025-04-06T04:17:24.352020Z","shell.execute_reply.started":"2025-04-06T04:17:24.241895Z","shell.execute_reply":"2025-04-06T04:17:24.350629Z"}},"outputs":[{"name":"stdout","text":"rna_graph.edge_index: tensor([], dtype=torch.int64)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-327ded1921a9>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mgnn_aggregator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGNN_Aggregator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mfinal_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn_aggregator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_representation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-327ded1921a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# (num_nodes, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/graph_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight, size)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n\u001b[0m\u001b[1;32m     85\u001b[0m                              size=size)\n\u001b[1;32m     86\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_rel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/torch_geometric.nn.conv.graph_conv_GraphConv_propagate_kpgpiob4.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_weight, size)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# End Propagate Forward Pre Hook ###########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mmutable_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# Run \"fused\" message and aggregation (if applicable).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_check_input\u001b[0;34m(self, edge_index, size)\u001b[0m\n\u001b[1;32m    233\u001b[0m                                  f\"type (got '{edge_index.dtype}')\")\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 raise ValueError(f\"Expected 'edge_index' to be two-dimensional\"\n\u001b[0m\u001b[1;32m    236\u001b[0m                                  f\" (got {edge_index.dim()} dimensions)\")\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected 'edge_index' to be two-dimensional (got 1 dimensions)"],"ename":"ValueError","evalue":"Expected 'edge_index' to be two-dimensional (got 1 dimensions)","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"from torch_geometric.data import Data\n\ndef create_rna_graph(msa_embedding):\n    # Assume a simple chain connectivity for now\n    num_nodes = msa_embedding.size(0)\n    # Connect each nucleotide to its next one: edge from i to i+1\n    edge_index = torch.tensor([[i, i+1] for i in range(num_nodes-1)] +\n                              [[i+1, i] for i in range(num_nodes-1)], dtype=torch.long).t().contiguous()\n    return Data(x=msa_embedding, edge_index=edge_index)\n\n# Example usage:\nrna_graph = create_rna_graph(final_representation)\nprint(\"Graph node features shape:\", rna_graph.x.shape)\nprint(\"Graph edge_index shape:\", rna_graph.edge_index.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:12:38.154455Z","iopub.status.idle":"2025-04-06T04:12:38.154672Z","shell.execute_reply":"2025-04-06T04:12:38.154585Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **1.3 Get Graphs from MSA Embeddings of Training Data**","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ngraph_list=[]\n\nfor idx, row in tqdm(train_sequences.iterrows()):\n    target_id = row['target_id']\n    sequence = row['sequence']\n\n    # Filter coordinates for this target\n    target_coords = train_labels[train_labels['ID'].str.startswith(target_id)]\n    \n    if len(target_coords) == 0:\n        print(f\"No coordinates found for {target_id}, skipping\")\n        continue\n\n    seq_msa = get_msa_embedding(sequence)\n    graph = create_rna_graph(seq_msa)\n\n    graph_list.append(graph)\n\nprint(graph_data_list[0])\nprint(len(graph_data_list))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T04:12:38.155182Z","iopub.status.idle":"2025-04-06T04:12:38.155395Z","shell.execute_reply":"2025-04-06T04:12:38.155317Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **📌 Step 2: Physics-Based Refinement**\nEven if ML predicts **good** RNA structures, **fine-tuning with physics-based methods** improves accuracy.\n\n---\n\n## **2.1 Use Rosetta for Energy Minimization**\nRosetta is a **powerful molecular modeling software** that refines predicted structures.\n\n### **🔹 Steps for Using Rosetta:**\n1. **Convert ML predictions to PDB format**  \n2. **Run Rosetta minimization** to relax the structure  \n3. **Extract refined coordinates** for submission  \n\n### **🔹 Code: Convert Predictions to PDB Format**\n","metadata":{}},{"cell_type":"code","source":"def write_pdb(predictions, sequence, output_file=\"rna_model.pdb\"):\n    \"\"\"Writes RNA coordinates to PDB format\"\"\"\n    with open(output_file, \"w\") as f:\n        for i, (x, y, z) in enumerate(predictions):\n            resname = sequence[i]\n            f.write(f\"HETATM {i+1:4d}  C1'  {resname} A   {i+1:3d}     {x:8.3f}{y:8.3f}{z:8.3f}  1.00  0.00\\n\")\n    print(f\"PDB file saved: {output_file}\")\n\n# Example usage\ndummy_predictions = np.random.rand(10, 3)  # Example (x, y, z) predictions\nwrite_pdb(dummy_predictions, \"GGGAAACCC\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:06:15.952111Z","iopub.execute_input":"2025-04-05T19:06:15.952489Z","iopub.status.idle":"2025-04-05T19:06:16.015313Z","shell.execute_reply.started":"2025-04-05T19:06:15.952414Z","shell.execute_reply":"2025-04-05T19:06:16.013957Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-36ee84b57d30>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdummy_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Example (x, y, z) predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mwrite_pdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GGGAAACCC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-48-36ee84b57d30>\u001b[0m in \u001b[0;36mwrite_pdb\u001b[0;34m(predictions, sequence, output_file)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mresname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"HETATM {i+1:4d}  C1'  {resname} A   {i+1:3d}     {x:8.3f}{y:8.3f}{z:8.3f}  1.00  0.00\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"PDB file saved: {output_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: string index out of range"],"ename":"IndexError","evalue":"string index out of range","output_type":"error"}],"execution_count":48},{"cell_type":"markdown","source":"### **🔹 Command: Run Rosetta Refinement**\nAfter converting ML predictions to PDB format, we refine them using Rosetta:","metadata":{}},{"cell_type":"code","source":"rosetta_scripts.default.linuxgccrelease -s rna_model.pdb -parser:protocol rna_minimize.xml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T18:03:46.886629Z","iopub.status.idle":"2025-03-29T18:03:46.887082Z","shell.execute_reply":"2025-03-29T18:03:46.886840Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **2.2 Use Molecular Dynamics (MD) Simulation**\nMolecular Dynamics (MD) uses physics-based **force fields** to refine RNA structures.\n\n### **🔹 Steps for MD Refinement**\n1. **Use OpenMM / GROMACS** to set up RNA simulation.  \n2. **Minimize energy** and relax RNA structure.  \n3. **Extract final coordinates** after stabilization.  \n\n### **🔹 Code: Run MD Simulation (OpenMM)**","metadata":{}},{"cell_type":"code","source":"from simtk.openmm.app import *\nfrom simtk.openmm import *\nfrom simtk.unit import *\n\ndef run_md_simulation(pdb_file, output_file=\"rna_relaxed.pdb\"):\n    \"\"\"Performs energy minimization using OpenMM\"\"\"\n    pdb = PDBFile(pdb_file)\n    forcefield = ForceField('amber99sb.xml', 'tip3p.xml')\n\n    system = forcefield.createSystem(pdb.topology, nonbondedMethod=NoCutoff, constraints=HBonds)\n    integrator = LangevinIntegrator(300*kelvin, 1/picosecond, 0.002*picoseconds)\n\n    simulation = Simulation(pdb.topology, system, integrator)\n    simulation.context.setPositions(pdb.positions)\n    \n    # Minimize energy\n    simulation.minimizeEnergy()\n    \n    # Save refined structure\n    positions = simulation.context.getState(getPositions=True).getPositions()\n    PDBFile.writeFile(simulation.topology, positions, open(output_file, 'w'))\n    print(f\"Refined PDB saved: {output_file}\")\n\n# Example usage\nrun_md_simulation(\"rna_model.pdb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T18:03:46.888226Z","iopub.status.idle":"2025-03-29T18:03:46.888600Z","shell.execute_reply":"2025-03-29T18:03:46.888418Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"🔹 **Why is this useful?**\n- Ensures the RNA model follows **physical constraints**.\n- Reduces **structural artifacts** from ML predictions.\n\n---\n\n# **📌 Step 3: Combining Everything for Best Accuracy**\nWe now **combine ML + MSA + Physics-based methods** to generate final predictions.\n\n### **🔹 Final Workflow**\n1. **Train ML Model (GNN/Transformer)**\n   - Inputs: RNA sequence + MSA features.\n   - Outputs: Predicted (x, y, z) coordinates.\n2. **Refine with Rosetta**\n   - Convert ML output to **PDB format**.\n   - Run **energy minimization**.\n3. **Further Relaxation with Molecular Dynamics (MD)**\n   - Ensure **stable structure** with OpenMM/GROMACS.\n4. **Format Predictions for Submission**\n   - Extract final (x, y, z) from PDB.\n\n---\n\n# **🚀 Next Steps**\n✅ **Train ML model on full dataset (GNN + Transformer)**  \n✅ **Benchmark ML vs. Rosetta vs. MD Refinement**  \n✅ **Optimize final submission** with hybrid ML + physics approach  ","metadata":{}}]}